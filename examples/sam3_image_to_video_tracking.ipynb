{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a2ce5d1",
   "metadata": {},
   "source": [
    "## SAM 3: Segmenta√ß√£o de Imagem e Propaga√ß√£o em V√≠deo com Exporta√ß√£o COCO\n",
    "\n",
    "Este notebook demonstra como:\n",
    "\n",
    "1. **Segmentar uma imagem** usando prompts de texto ou visuais\n",
    "2. **Propagar as anota√ß√µes** para um v√≠deo completo\n",
    "3. **Visualizar todos os frames** com as anota√ß√µes\n",
    "4. **Salvar as anota√ß√µes** em formato COCO JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91441353",
   "metadata": {},
   "outputs": [],
   "source": [
    "using_colab = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755f16e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if using_colab:\n",
    "    import torch\n",
    "    import torchvision\n",
    "    print(\"PyTorch version:\", torch.__version__)\n",
    "    print(\"Torchvision version:\", torchvision.__version__)\n",
    "    print(\"CUDA is available:\", torch.cuda.is_available())\n",
    "    import sys\n",
    "    !{sys.executable} -m pip install opencv-python matplotlib scikit-learn\n",
    "    !{sys.executable} -m pip install 'git+https://github.com/facebookresearch/sam3.git'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449be011",
   "metadata": {},
   "source": [
    "## Setup e Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cec94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "from datetime import datetime\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "import sam3\n",
    "from sam3 import build_sam3_image_model\n",
    "from sam3.model_builder import build_sam3_video_predictor\n",
    "from sam3.model.box_ops import box_xywh_to_cxcywh\n",
    "from sam3.model.sam3_image_processor import Sam3Processor\n",
    "from sam3.visualization_utils import (\n",
    "    draw_box_on_image,\n",
    "    load_frame,\n",
    "    normalize_bbox,\n",
    "    plot_results,\n",
    "    prepare_masks_for_visualization,\n",
    "    visualize_formatted_frame_output,\n",
    ")\n",
    "\n",
    "sam3_root = os.path.join(os.path.dirname(sam3.__file__), \"..\")\n",
    "\n",
    "# Configurar matplotlib\n",
    "plt.rcParams[\"axes.titlesize\"] = 12\n",
    "plt.rcParams[\"figure.titlesize\"] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868b1fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Habilitar tf32 para GPUs Ampere\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "# Usar bfloat16 para todo o notebook\n",
    "torch.autocast(\"cuda\", dtype=torch.bfloat16).__enter__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd167d91",
   "metadata": {},
   "source": [
    "## Fun√ß√µes Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64af45b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_to_rel_coords(coords, IMG_WIDTH, IMG_HEIGHT, coord_type=\"point\"):\n",
    "    \"\"\"Converte coordenadas absolutas para relativas (0-1)\n",
    "    \n",
    "    Args:\n",
    "        coords: Lista de coordenadas\n",
    "        coord_type: 'point' para [x, y] ou 'box' para [x, y, w, h]\n",
    "    \"\"\"\n",
    "    if coord_type == \"point\":\n",
    "        return [[x / IMG_WIDTH, y / IMG_HEIGHT] for x, y in coords]\n",
    "    elif coord_type == \"box\":\n",
    "        return [\n",
    "            [x / IMG_WIDTH, y / IMG_HEIGHT, w / IMG_WIDTH, h / IMG_HEIGHT]\n",
    "            for x, y, w, h in coords\n",
    "        ]\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown coord_type: {coord_type}\")\n",
    "\n",
    "\n",
    "def propagate_in_video(predictor, session_id):\n",
    "    \"\"\"Propaga as anota√ß√µes do frame inicial para todo o v√≠deo\"\"\"\n",
    "    outputs_per_frame = {}\n",
    "    for response in predictor.handle_stream_request(\n",
    "        request=dict(\n",
    "            type=\"propagate_in_video\",\n",
    "            session_id=session_id,\n",
    "        )\n",
    "    ):\n",
    "        outputs_per_frame[response[\"frame_index\"]] = response[\"outputs\"]\n",
    "    return outputs_per_frame\n",
    "\n",
    "\n",
    "def mask_to_rle(binary_mask):\n",
    "    \"\"\"Converte m√°scara bin√°ria para formato RLE (Run Length Encoding)\"\"\"\n",
    "    rle = {'counts': [], 'size': list(binary_mask.shape)}\n",
    "    counts = rle.get('counts')\n",
    "    \n",
    "    # Flatten mask\n",
    "    flat_mask = binary_mask.ravel(order='F')\n",
    "    \n",
    "    # Encode RLE\n",
    "    last_val = 0\n",
    "    count = 0\n",
    "    for val in flat_mask:\n",
    "        if val != last_val:\n",
    "            counts.append(count)\n",
    "            count = 1\n",
    "            last_val = val\n",
    "        else:\n",
    "            count += 1\n",
    "    counts.append(count)\n",
    "    \n",
    "    return rle\n",
    "\n",
    "\n",
    "def mask_to_bbox(binary_mask):\n",
    "    \"\"\"Extrai bounding box de uma m√°scara bin√°ria no formato COCO [x, y, width, height]\"\"\"\n",
    "    rows = np.any(binary_mask, axis=1)\n",
    "    cols = np.any(binary_mask, axis=0)\n",
    "    \n",
    "    if not rows.any() or not cols.any():\n",
    "        return [0, 0, 0, 0]\n",
    "    \n",
    "    rmin, rmax = np.where(rows)[0][[0, -1]]\n",
    "    cmin, cmax = np.where(cols)[0][[0, -1]]\n",
    "    \n",
    "    return [int(cmin), int(rmin), int(cmax - cmin + 1), int(rmax - rmin + 1)]\n",
    "\n",
    "\n",
    "def calculate_mask_area(binary_mask):\n",
    "    \"\"\"Calcula a √°rea de uma m√°scara bin√°ria\"\"\"\n",
    "    return int(np.sum(binary_mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da62aaee",
   "metadata": {},
   "source": [
    "## Parte 1: Segmenta√ß√£o de Imagem com Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3189992d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir modelo de imagem\n",
    "bpe_path = f\"{sam3_root}/assets/bpe_simple_vocab_16e6.txt.gz\"\n",
    "image_model = build_sam3_image_model(bpe_path=bpe_path)\n",
    "print(\"Modelo de imagem carregado com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d191ce6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar imagem\n",
    "image_path = f\"{sam3_root}/assets/images/test_image.jpg\"\n",
    "image = Image.open(image_path)\n",
    "width, height = image.size\n",
    "print(f\"Imagem carregada: {width}x{height}\")\n",
    "\n",
    "# Configurar processador\n",
    "processor = Sam3Processor(image_model, confidence_threshold=0.5)\n",
    "inference_state = processor.set_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fcd3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentar com prompt de texto\n",
    "# Voc√™ pode alterar o prompt aqui\n",
    "prompt_text = \"monitor\"\n",
    "\n",
    "processor.reset_all_prompts(inference_state)\n",
    "inference_state = processor.set_text_prompt(state=inference_state, prompt=prompt_text)\n",
    "\n",
    "# Visualizar resultados\n",
    "img0 = Image.open(image_path)\n",
    "plot_results(img0, inference_state)\n",
    "print(f\"Segmenta√ß√£o completa com prompt: '{prompt_text}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16852d1d",
   "metadata": {},
   "source": [
    "### Alternativa: Usar Prompt Visual (Box)\n",
    "\n",
    "Descomente o c√≥digo abaixo se preferir usar um bounding box ao inv√©s de texto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63052a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Exemplo com bounding box (formato x, y, w, h)\n",
    "# box_input_xywh = torch.tensor([480.0, 290.0, 110.0, 360.0]).view(-1, 4)\n",
    "# box_input_cxcywh = box_xywh_to_cxcywh(box_input_xywh)\n",
    "# norm_box_cxcywh = normalize_bbox(box_input_cxcywh, width, height).flatten().tolist()\n",
    "\n",
    "# processor.reset_all_prompts(inference_state)\n",
    "# inference_state = processor.add_geometric_prompt(\n",
    "#     state=inference_state, box=norm_box_cxcywh, label=True\n",
    "# )\n",
    "\n",
    "# # Visualizar com box\n",
    "# image_with_box = draw_box_on_image(img0, box_input_xywh.flatten().tolist())\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# plt.imshow(image_with_box)\n",
    "# plt.axis(\"off\")\n",
    "# plt.title(\"Imagem com Bounding Box\")\n",
    "# plt.show()\n",
    "\n",
    "# plot_results(img0, inference_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed9b9f1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚ö° ATALHO: Usar Primeiro Frame do V√≠deo\n",
    "\n",
    "**Se voc√™ quer segmentar o PRIMEIRO FRAME DO V√çDEO e propagar**, siga estes passos:\n",
    "\n",
    "1. **Execute primeiro** as c√©lulas da \"Parte 2: Propaga√ß√£o em V√≠deo\" para carregar o v√≠deo\n",
    "2. **Depois volte aqui** e use o c√≥digo abaixo:\n",
    "\n",
    "```python\n",
    "# Use este c√≥digo DEPOIS de carregar o v√≠deo na Parte 2\n",
    "if isinstance(video_frames_for_vis[0], str):\n",
    "    first_frame = Image.open(video_frames_for_vis[0])\n",
    "else:\n",
    "    first_frame = Image.fromarray(video_frames_for_vis[0])\n",
    "\n",
    "# Reconfigure o processador com o primeiro frame\n",
    "inference_state = processor.set_image(first_frame)\n",
    "width, height = first_frame.size\n",
    "\n",
    "# Agora segmente este frame (use o mesmo c√≥digo de prompt/box acima)\n",
    "```\n",
    "\n",
    "3. **Continue com a Parte 2** normalmente, usando o **mesmo** `prompt_text`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe6fec9",
   "metadata": {},
   "source": [
    "## Parte 2: Propaga√ß√£o em V√≠deo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16440bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar v√≠deo\n",
    "video_path = f\"{sam3_root}/assets/videos/0001\"\n",
    "\n",
    "# Carregar frames para visualiza√ß√£o\n",
    "if isinstance(video_path, str) and video_path.endswith(\".mp4\"):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    video_frames_for_vis = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        video_frames_for_vis.append(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    cap.release()\n",
    "else:\n",
    "    video_frames_for_vis = glob.glob(os.path.join(video_path, \"*.jpg\"))\n",
    "    try:\n",
    "        video_frames_for_vis.sort(\n",
    "            key=lambda p: int(os.path.splitext(os.path.basename(p))[0])\n",
    "        )\n",
    "    except ValueError:\n",
    "        print(f\"Frames n√£o est√£o no formato '<frame_index>.jpg', usando ordem lexicogr√°fica\")\n",
    "        video_frames_for_vis.sort()\n",
    "\n",
    "print(f\"V√≠deo carregado com {len(video_frames_for_vis)} frames\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14f3d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciar sess√£o de infer√™ncia\n",
    "response = video_predictor.handle_request(\n",
    "    request=dict(\n",
    "        type=\"start_session\",\n",
    "        resource_path=video_path,\n",
    "    )\n",
    ")\n",
    "session_id = response[\"session_id\"]\n",
    "print(f\"Sess√£o iniciada: {session_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e831dffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrair o primeiro frame do v√≠deo para segmenta√ß√£o inicial\n",
    "if isinstance(video_frames_for_vis[0], str):\n",
    "    first_frame = Image.open(video_frames_for_vis[0])\n",
    "    first_frame_array = np.array(first_frame)\n",
    "else:\n",
    "    first_frame_array = video_frames_for_vis[0]\n",
    "    first_frame = Image.fromarray(first_frame_array)\n",
    "\n",
    "width, height = first_frame.size\n",
    "print(f\"Primeiro frame extra√≠do: {width}x{height}\")\n",
    "\n",
    "# Visualizar o primeiro frame\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(first_frame_array)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Frame 0 - Frame Inicial do V√≠deo\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a6d97f",
   "metadata": {},
   "source": [
    "## Parte 2: Segmentar o Primeiro Frame com Prompt\n",
    "\n",
    "‚ö†Ô∏è **IMPORTANTE**: Aqui segmentamos o **primeiro frame do v√≠deo (frame 0)**.\n",
    "Essa segmenta√ß√£o ser√° depois propagada para todos os outros frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1af856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir modelo de imagem\n",
    "bpe_path = f\"{sam3_root}/assets/bpe_simple_vocab_16e6.txt.gz\"\n",
    "image_model = build_sam3_image_model(bpe_path=bpe_path)\n",
    "print(\"Modelo de imagem carregado com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8de87ae",
   "metadata": {},
   "source": [
    "## Parte 4: Visualiza√ß√£o de Todos os Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9a18cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentar o primeiro frame com prompt de texto\n",
    "# üéØ Voc√™ pode alterar o prompt aqui\n",
    "prompt_text = \"person\"\n",
    "\n",
    "processor.reset_all_prompts(inference_state)\n",
    "inference_state = processor.set_text_prompt(state=inference_state, prompt=prompt_text)\n",
    "\n",
    "# Visualizar resultados da segmenta√ß√£o\n",
    "plot_results(first_frame, inference_state)\n",
    "print(f\"‚úÖ Segmenta√ß√£o do frame 0 completa com prompt: '{prompt_text}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef641382",
   "metadata": {},
   "source": [
    "## Parte 5: Exportar Anota√ß√µes para Formato COCO JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff19492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Exemplo com bounding box (formato x, y, w, h)\n",
    "# # Ajuste as coordenadas para o seu primeiro frame\n",
    "# box_input_xywh = torch.tensor([480.0, 290.0, 110.0, 360.0]).view(-1, 4)\n",
    "# box_input_cxcywh = box_xywh_to_cxcywh(box_input_xywh)\n",
    "# norm_box_cxcywh = normalize_bbox(box_input_cxcywh, width, height).flatten().tolist()\n",
    "\n",
    "# processor.reset_all_prompts(inference_state)\n",
    "# inference_state = processor.add_geometric_prompt(\n",
    "#     state=inference_state, box=norm_box_cxcywh, label=True\n",
    "# )\n",
    "\n",
    "# # Visualizar com box\n",
    "# image_with_box = draw_box_on_image(first_frame, box_input_xywh.flatten().tolist())\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# plt.imshow(image_with_box)\n",
    "# plt.axis(\"off\")\n",
    "# plt.title(\"Frame 0 com Bounding Box\")\n",
    "# plt.show()\n",
    "\n",
    "# plot_results(first_frame, inference_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0a6c50",
   "metadata": {},
   "source": [
    "## Parte 3: Propagar Segmenta√ß√£o para Todo o V√≠deo\n",
    "\n",
    "üîÑ Agora vamos propagar a segmenta√ß√£o do frame 0 para todos os frames do v√≠deo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb56e04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar GPUs\n",
    "gpus_to_use = range(torch.cuda.device_count())\n",
    "# Para usar apenas uma GPU:\n",
    "# gpus_to_use = [torch.cuda.current_device()]\n",
    "\n",
    "# Construir preditor de v√≠deo\n",
    "video_predictor = build_sam3_video_predictor(gpus_to_use=gpus_to_use)\n",
    "print(f\"Preditor de v√≠deo constru√≠do com {len(gpus_to_use)} GPU(s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4d28d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionar prompt de texto no frame 0\n",
    "# Use o mesmo prompt da segmenta√ß√£o de imagem ou altere conforme necess√°rio\n",
    "video_prompt_text = \"person\"\n",
    "frame_idx = 0\n",
    "\n",
    "response = video_predictor.handle_request(\n",
    "    request=dict(\n",
    "        type=\"add_prompt\",\n",
    "        session_id=session_id,\n",
    "        frame_index=frame_idx,\n",
    "        text=video_prompt_text,\n",
    "    )\n",
    ")\n",
    "out = response[\"outputs\"]\n",
    "\n",
    "# Visualizar resultado no frame inicial\n",
    "plt.close(\"all\")\n",
    "visualize_formatted_frame_output(\n",
    "    frame_idx,\n",
    "    video_frames_for_vis,\n",
    "    outputs_list=[prepare_masks_for_visualization({frame_idx: out})],\n",
    "    titles=[f\"Frame {frame_idx} com prompt: '{video_prompt_text}'\"],\n",
    "    figsize=(8, 6),\n",
    ")\n",
    "print(f\"Prompt '{video_prompt_text}' adicionado no frame {frame_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e81cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Propagar anota√ß√µes para todo o v√≠deo\n",
    "print(\"Propagando anota√ß√µes por todo o v√≠deo...\")\n",
    "outputs_per_frame = propagate_in_video(video_predictor, session_id)\n",
    "print(f\"Propaga√ß√£o completa! {len(outputs_per_frame)} frames processados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359684e4",
   "metadata": {},
   "source": [
    "## Parte 3: Visualiza√ß√£o de Todos os Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82bf1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar m√°scaras para visualiza√ß√£o\n",
    "formatted_outputs = prepare_masks_for_visualization(outputs_per_frame)\n",
    "\n",
    "# Visualizar TODOS os frames (pode gerar muitas imagens!)\n",
    "# Para v√≠deos longos, considere usar um stride maior\n",
    "vis_frame_stride = 1  # Altere para 5, 10, etc. para pular frames\n",
    "\n",
    "print(f\"Visualizando frames com stride={vis_frame_stride}\")\n",
    "plt.close(\"all\")\n",
    "\n",
    "for frame_idx in range(0, len(formatted_outputs), vis_frame_stride):\n",
    "    visualize_formatted_frame_output(\n",
    "        frame_idx,\n",
    "        video_frames_for_vis,\n",
    "        outputs_list=[formatted_outputs],\n",
    "        titles=[f\"SAM 3 - Frame {frame_idx}\"],\n",
    "        figsize=(8, 6),\n",
    "    )\n",
    "\n",
    "print(f\"Visualiza√ß√£o completa de {len(range(0, len(formatted_outputs), vis_frame_stride))} frames\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e34273",
   "metadata": {},
   "source": [
    "## Parte 4: Exportar Anota√ß√µes para Formato COCO JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886bc9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_coco_json(outputs_per_frame, video_frames, output_path, video_name=\"video\"):\n",
    "    \"\"\"\n",
    "    Exporta as anota√ß√µes do SAM 3 para formato COCO JSON\n",
    "    \n",
    "    Args:\n",
    "        outputs_per_frame: Dicion√°rio com outputs por frame\n",
    "        video_frames: Lista de paths ou arrays dos frames\n",
    "        output_path: Caminho para salvar o arquivo JSON\n",
    "        video_name: Nome do v√≠deo\n",
    "    \"\"\"\n",
    "    # Estrutura base COCO\n",
    "    coco_data = {\n",
    "        \"info\": {\n",
    "            \"description\": \"SAM 3 Video Annotations\",\n",
    "            \"version\": \"1.0\",\n",
    "            \"year\": datetime.now().year,\n",
    "            \"date_created\": datetime.now().isoformat(),\n",
    "        },\n",
    "        \"licenses\": [],\n",
    "        \"images\": [],\n",
    "        \"annotations\": [],\n",
    "        \"categories\": [],\n",
    "    }\n",
    "    \n",
    "    # Obter dimens√µes do frame\n",
    "    if isinstance(video_frames[0], str):\n",
    "        first_frame = np.array(Image.open(video_frames[0]))\n",
    "    else:\n",
    "        first_frame = video_frames[0]\n",
    "    \n",
    "    height, width = first_frame.shape[:2]\n",
    "    \n",
    "    # Coletar todas as categorias (object IDs) √∫nicas\n",
    "    all_object_ids = set()\n",
    "    for frame_data in outputs_per_frame.values():\n",
    "        for obj_id in frame_data.keys():\n",
    "            all_object_ids.add(obj_id)\n",
    "    \n",
    "    # Criar categorias\n",
    "    for obj_id in sorted(all_object_ids):\n",
    "        coco_data[\"categories\"].append({\n",
    "            \"id\": int(obj_id),\n",
    "            \"name\": f\"object_{obj_id}\",\n",
    "            \"supercategory\": \"object\",\n",
    "        })\n",
    "    \n",
    "    annotation_id = 1\n",
    "    \n",
    "    # Processar cada frame\n",
    "    for frame_idx in sorted(outputs_per_frame.keys()):\n",
    "        # Adicionar informa√ß√£o da imagem\n",
    "        image_id = frame_idx + 1\n",
    "        if isinstance(video_frames[frame_idx], str):\n",
    "            file_name = os.path.basename(video_frames[frame_idx])\n",
    "        else:\n",
    "            file_name = f\"{video_name}_frame_{frame_idx:05d}.jpg\"\n",
    "        \n",
    "        coco_data[\"images\"].append({\n",
    "            \"id\": image_id,\n",
    "            \"file_name\": file_name,\n",
    "            \"height\": height,\n",
    "            \"width\": width,\n",
    "            \"frame_index\": frame_idx,\n",
    "        })\n",
    "        \n",
    "        # Processar cada objeto no frame\n",
    "        frame_data = outputs_per_frame[frame_idx]\n",
    "        for obj_id, obj_data in frame_data.items():\n",
    "            # Extrair m√°scara\n",
    "            if isinstance(obj_data, dict) and \"mask\" in obj_data:\n",
    "                mask = obj_data[\"mask\"]\n",
    "            else:\n",
    "                mask = obj_data\n",
    "            \n",
    "            # Converter para numpy array se necess√°rio\n",
    "            if torch.is_tensor(mask):\n",
    "                mask = mask.cpu().numpy()\n",
    "            \n",
    "            # Garantir que a m√°scara √© bin√°ria\n",
    "            binary_mask = (mask > 0).astype(np.uint8)\n",
    "            \n",
    "            # Calcular bbox e √°rea\n",
    "            bbox = mask_to_bbox(binary_mask)\n",
    "            area = calculate_mask_area(binary_mask)\n",
    "            \n",
    "            # Pular se a m√°scara estiver vazia\n",
    "            if area == 0:\n",
    "                continue\n",
    "            \n",
    "            # Converter m√°scara para RLE\n",
    "            rle = mask_to_rle(binary_mask)\n",
    "            \n",
    "            # Adicionar anota√ß√£o\n",
    "            coco_data[\"annotations\"].append({\n",
    "                \"id\": annotation_id,\n",
    "                \"image_id\": image_id,\n",
    "                \"category_id\": int(obj_id),\n",
    "                \"segmentation\": rle,\n",
    "                \"area\": area,\n",
    "                \"bbox\": bbox,\n",
    "                \"iscrowd\": 0,\n",
    "            })\n",
    "            \n",
    "            annotation_id += 1\n",
    "    \n",
    "    # Salvar JSON\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(coco_data, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nAnota√ß√µes COCO salvas em: {output_path}\")\n",
    "    print(f\"  - Total de imagens: {len(coco_data['images'])}\")\n",
    "    print(f\"  - Total de anota√ß√µes: {len(coco_data['annotations'])}\")\n",
    "    print(f\"  - Total de categorias: {len(coco_data['categories'])}\")\n",
    "    \n",
    "    return coco_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76731b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar para COCO JSON\n",
    "output_json_path = f\"{sam3_root}/outputs/annotations_coco.json\"\n",
    "\n",
    "# Criar diret√≥rio de sa√≠da se n√£o existir\n",
    "os.makedirs(os.path.dirname(output_json_path), exist_ok=True)\n",
    "\n",
    "# Exportar\n",
    "coco_annotations = export_to_coco_json(\n",
    "    outputs_per_frame=outputs_per_frame,\n",
    "    video_frames=video_frames_for_vis,\n",
    "    output_path=output_json_path,\n",
    "    video_name=\"sam3_video\"\n",
    ")\n",
    "\n",
    "print(\"\\nExporta√ß√£o completa!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6f0d14",
   "metadata": {},
   "source": [
    "## Verificar Anota√ß√µes Exportadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc33f700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar e exibir estat√≠sticas do arquivo COCO\n",
    "with open(output_json_path, 'r') as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "print(\"\\n=== Estat√≠sticas das Anota√ß√µes COCO ===\")\n",
    "print(f\"N√∫mero de frames anotados: {len(coco_data['images'])}\")\n",
    "print(f\"N√∫mero total de anota√ß√µes: {len(coco_data['annotations'])}\")\n",
    "print(f\"N√∫mero de categorias/objetos: {len(coco_data['categories'])}\")\n",
    "print(\"\\nCategorias detectadas:\")\n",
    "for cat in coco_data['categories']:\n",
    "    cat_annotations = [ann for ann in coco_data['annotations'] if ann['category_id'] == cat['id']]\n",
    "    print(f\"  - {cat['name']} (ID: {cat['id']}): {len(cat_annotations)} anota√ß√µes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f3f04e",
   "metadata": {},
   "source": [
    "## Limpeza e Encerramento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d273e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fechar sess√£o de infer√™ncia\n",
    "_ = video_predictor.handle_request(\n",
    "    request=dict(\n",
    "        type=\"close_session\",\n",
    "        session_id=session_id,\n",
    "    )\n",
    ")\n",
    "print(\"Sess√£o encerrada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdead2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desligar preditor\n",
    "video_predictor.shutdown()\n",
    "print(\"Preditor desligado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d65e10",
   "metadata": {},
   "source": [
    "## Resumo\n",
    "\n",
    "Este notebook demonstrou:\n",
    "\n",
    "‚úÖ **Segmenta√ß√£o de imagem** com prompt de texto ou visual  \n",
    "‚úÖ **Propaga√ß√£o de anota√ß√µes** em v√≠deo completo  \n",
    "‚úÖ **Visualiza√ß√£o de todos os frames** com as m√°scaras  \n",
    "‚úÖ **Exporta√ß√£o para COCO JSON** com RLE, bboxes e √°reas  \n",
    "\n",
    "O arquivo COCO gerado pode ser usado para:\n",
    "- Treinamento de modelos de detec√ß√£o/segmenta√ß√£o\n",
    "- Avalia√ß√£o de performance\n",
    "- An√°lise de objetos ao longo do tempo\n",
    "- Integra√ß√£o com outras ferramentas de vis√£o computacional"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
